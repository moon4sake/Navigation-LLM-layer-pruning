#!/bin/bash

#python testttt.py --pr_method BI --base_model Gemma2-2b
#python testttt.py --pr_method ppl --base_model Gemma2-2b
#python testttt.py --pr_method vw --base_model Gemma2-2b

cd /public/ly/SBF/
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  tail  --remove_layer 1 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail1/
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  tail  --remove_layer 2 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail2/
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 python finetune_pruned_qlora.py --base_model Gemma2-2b --save_model  --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_BI/  --pr_method BI
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 python finetune_pruned_qlora.py --base_model Gemma2-2b --save_model  --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_taylor/  --pr_method taylor
#cd /public/MountData/yaolu/lm-evaluation-harness
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Vicuna_7B_tail16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Vicuna_7B_tail16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Vicuna_7B_ppl16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Vicuna_7B_ppl16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Vicuna_7B_random16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Vicuna_7B_random16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_tail16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_tail16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=2,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_ppl16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_ppl16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=2,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_random16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_random16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=2,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_llama3-8b_magnitude_l1_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_llama3-8b_magnitude_l116/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Vicuna_7B_magnitude_l1_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Vicuna_7B_magnitude_l116/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_magnitude_l1_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_magnitude_l116/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_magnitude_l2_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_magnitude_l216/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_llama3-8b_magnitude_l2_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_llama3-8b_magnitude_l216/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail8/,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_magnitude_l2/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_magnitude_l28/,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l1_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_magnitude_l112/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_random12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_random12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,2 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l2_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_magnitude_l212/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_llama3-8b_tail16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_llama3-8b_tail16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_llama3-8b_random16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_llama3-8b_random16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_ppl_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_ppl12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_tail12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_tail12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_BI_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_BI12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_taylor_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_taylor12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lm_head/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lmhead+last_layer/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lm_head+last_two_layer,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lm_head+last_three_layer/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Vicuna_7B_alpaca_norm_lm_head+last_two_layer/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 16  --num_fewshot 0



#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail3/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail3/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail4/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail4/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail5/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail5/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail6/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail6/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random8/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_magnitude_l1/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_magnitude_l18/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail9/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail9/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail10/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail10/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail11/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail11/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail12/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail12/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail13/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail13/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail14/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail14/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_tail15/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail15/  --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method tail  --remove_layer 6 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_tail6/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method tail  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_tail12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method taylor  --remove_layer 6 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_taylor/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method taylor  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_taylor_12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method random  --remove_layer 6 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_random/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method random  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_random12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method ppl  --remove_layer 6 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_ppl/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method ppl  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_ppl_12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method BI  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_BI_12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method magnitude_l1  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l1_12/
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method magnitude_l2  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l2_12/

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random17/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random17/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random18/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random18/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random19/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random19/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random20/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random20/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  BI  --remove_layer 8 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_BI8/
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  BI  --remove_layer 16 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_BI16/
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 8 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_taylor8/
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 16 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_taylor16/

#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_taylor_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_taylor12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_random/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_random6/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_random12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_random12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_ppl_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_ppl12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_BI_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_BI12/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_ppl/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_ppl6/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Vicuna_7B_alpaca_last1/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Vicuna_7B_alpaca_last3/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l1_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_magnitude_l112/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Gemma2-2b_magnitude_l2_12/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_magnitude_l212/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_magnitude_l116/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/prune_Llama-3.1-8B-Instruct_random_16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_magnitude_l216/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0

### not finsih
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Gemma2-2b_alpaca_norm_lmhead/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Gemma2-2b_alpaca_last1/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Gemma2-2b_alpaca_last2/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Gemma2-2b_alpaca_last3/,trust_remote_code=True --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Qwen1.5-7B --save_model --pr_method taylor --remove_layer 8 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_taylor8/

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random22/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random22/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random23/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random23/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random24/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random24/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random25/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random25/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random26/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random26/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random27/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random27/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random28/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random28/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random29/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random29/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random30/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random30/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/prune_Gemma2-2b_tail_1/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Gemma2-2b_tail1/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_taylor16/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_taylor16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_taylor16/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor16/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Qwen1.5-7B_taylor8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Qwen1.5-7B_taylor8/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=0 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_random21/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_random21/ --tasks mmlu,cmmlu,coqa,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_taylor8/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lmhead/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_taylor8/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last1/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_taylor8/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last2/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1 --num_fewshot 0

#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor1_to_taylor2/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor2/ --remove_layer 2
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 3 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor2_to_taylor3/


#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor2_to_taylor3/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor3/ --remove_layer 3
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 4 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor3_to_taylor4/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor3_to_taylor4/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor4/ --remove_layer 4
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 5 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor4_to_taylor5/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor4_to_taylor5/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor5/ --remove_layer 5
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 6 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor5_to_taylor6/

#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor5_to_taylor6/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor6/ --remove_layer 6
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 7 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor6_to_taylor7/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor6_to_taylor7/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor7/ --remove_layer 7
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 8 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor7_to_taylor8/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor7_to_taylor8/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor8/ --remove_layer 8
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 9 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor8_to_taylor9/


#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor8_to_taylor9/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor9/ --remove_layer 9
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 10 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor9_to_taylor10/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor9_to_taylor10/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor10/ --remove_layer 10
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 11 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor10_to_taylor11/
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python iter_taylor.py --save_model --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor10_to_taylor11/ --lora_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor11/ --remove_layer 11
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 python finetune_pruned_gemma.py --base_model Gemma2-2b --save_model --pr_method  iter_taylor  --remove_layer 12 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor11_to_taylor12/

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor2_to_taylor3/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor3/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor3_to_taylor4/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor4/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor4_to_taylor5/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor5/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor5_to_taylor6/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor6/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor6_to_taylor7/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor7/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor7_to_taylor8/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor8/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor8_to_taylor9/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor9/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor9_to_taylor10/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor10/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor10_to_taylor11/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor11/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Gemma2-2b_taylor11_to_taylor12/,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Gemma2-2b_iter_taylor12/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 17  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 18  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 19  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 22  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 23  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 24  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 25  --save_model  --pr_method taylor
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Llama-3.1-8B-Instruct  --remove_layer 26  --save_model  --pr_method taylor


#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 17 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_17/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 18 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_18/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 19 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_19/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 20 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_20/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 21 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_21/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 22 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_22/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 23 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_23/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 24 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_24/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 25 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_25/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  taylor  --remove_layer 26 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_26/

#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_5/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_5/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_6/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_6/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_7/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_7/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_9/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_9/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_10/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_10/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_11/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_11/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_12/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_12/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_13/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_13/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_14/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_14/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_15/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_15/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_26/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor26/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_27/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_27/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_28/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_28/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_29/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_29/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_30/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_30/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size auto  --num_fewshot 0


#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_1/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_1/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_2/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_2/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_3/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_3/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_4/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_4/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/pruned_Llama-3.1-8B-Instruct_taylor_only29_1/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/taylor/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_only29_1/  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_Llama-3.1-8B-Instruct_alpaca_norm_lm_head+last_three_layer/,trust_remote_code=True,parallelize=True --tasks mmlu,winogrande  --device cuda:0  --batch_size 1  --num_fewshot 5
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/models--nvidia--Mistral-NeMo-Minitron-8B-Base/,trust_remote_code=True,parallelize=True --tasks mmlu,winogrande  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Baichuan2-7B-Base/models--baichuan-inc--Baichuan2-7B-Base/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/chatglm2-6b/models--THUDM--chatglm2-6b/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/LLAMA3_8B/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 4  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Meta-Llama-3.1-8B-Instruct/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/8c22764a7e3675c50d4c7c9a4edb474456022b16/,trust_remote_code=True,parallelize=True --tasks mmlu,winogrande  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Qwen1.5-7B/models--Qwen--Qwen1.5-7B/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Vicuna_7B_V1.5/models--lmsys--vicuna-7b-v1.5/,trust_remote_code=True,parallelize=True --tasks mmlu,winogrande  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Yi-1.5-6B/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/chatglm-6b/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Gemma_7B/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 4  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/chatglm2-6b/models--THUDM--chatglm2-6b/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Baichuan2-7B-Base/models--baichuan-inc--Baichuan2-7B-Base/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/pruned_Llama-3.1-8B-Instruct_taylor8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/finetuned_lora_dolly_Llama-3.1-8B-Instruct_taylor8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/partial_tuing_alpaca_Llama-3.1-8B-Instruct_last3_8/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 4  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Llama-3.1-8B-Instruct_taylor11totaylor12/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_12/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 4  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Llama-3.1-8B-Instruct_taylor7totaylor8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/Iterative_pruned_Llama-3.1-8B-Instruct_tail7totail8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail_8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/partial_tuing_alpaca_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/iter_8/recheck/Iterative_pruned_Llama-3.1-8B-Instruct_taylor15totaylor16/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/iter_8/recheck/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_16  --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_alpaca_tail_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_alpaca_taylor_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 8  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/iter_4/Iterative_pruned_Llama-3.1-8B-Instruct_taylor4totaylor8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/iter_4/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_taylor_8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/iter_4/Iterative_pruned_Llama-3.1-8B-Instruct_tail4totail8/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/iter_4/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_tail_8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/Iterative_pruned_Gemma2-2b_taylor3totaylor6/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/iter/finetuned_lora_alpaca_iter3_Gemma2-2b_taylor6/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#cd /public/ly/SBF
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Vicuna_7B --save_model  --pr_method taylor --remove_layer 8
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python prune_llm.py --base_model Vicuna_7B --save_model  --pr_method taylor --remove_layer 16
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Vicuna_7B --save_model --pr_method  taylor  --remove_layer 8 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/pruned_Vicuna_7B_taylor_8/
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Vicuna_7B --save_model --pr_method  taylor  --remove_layer 16 --prune_model_path /public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/pruned_Vicuna_7B_taylor_16/
cd /public/MountData/yaolu/lm-evaluation-harness

#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/partial_tuing_Llama-3.1-8B-Instruct_alpaca_iter1_taylor_last3_8/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_alpaca_taylor_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/Iterative_lora/partial_tuing_Llama-3.1-8B-Instruct_alpaca_iter1_taylor_last3_16/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/pruned_Vicuna_7B_taylor_8/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/finetuned_lora_alpaca_Vicuna_7B_taylor8/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/pruned_Vicuna_7B_taylor_8/,trust_remote_code=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/finetuned_lora_alpaca_Vicuna_7B_taylor16/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_finetuned_dolly_Llama-3.1-8B-Instruct_tail8/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_mmlu_tail_Llama-3.1-8B-Instruct_last3_8/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_oneshot_alpaca_tail_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_oneshot_alpaca_taylor_Llama-3.1-8B-Instruct_last3_16/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_tail_iter1_last3_8/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_tail_iter1_last3_16/,trust_remote_code=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_finetuned_dolly_Llama-3.1-8B-Instruct_tail10_last3/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_finetuned_dolly_Llama-3.1-8B-Instruct_tail12_last3/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,2,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last3_0/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last3_10/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last3_12/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_tuing_Llama-3.1-8B-Instruct_alpaca_last3_6/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,1,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/partial_finetuned_dolly_Llama-3.1-8B-Instruct_tail6_last3/,trust_remote_code=True,parallelize=True --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 2  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,1,2,3 TRANSFORMERS_OFFLINE=1 lm_eval --model hf  --model_args pretrained=/public/MountData/yaolu/LLM_pretrained/Meta-Llama-3.1-8B-Instruct/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/8c22764a7e3675c50d4c7c9a4edb474456022b16/,trust_remote_code=True,parallelize=True,peft=/public/MountData/yaolu/LLM_pretrained/pruned_model/oneshot/finetuned_lora_alpaca_Llama-3.1-8B-Instruct_ori_0/ --tasks mmlu,cmmlu,piqa,openbookqa,winogrande,hellaswag,arc_easy,arc_challenge  --device cuda:0  --batch_size 1  --num_fewshot 0
#CUDA_VISIBLE_DEVICES=0,1,2,3 TRANSFORMERS_OFFLINE=1 python finetune_pruned.py --base_model Llama-3.1-8B-Instruct --save_model --pr_method  none  --remove_layer 0 --prune_model_path /public/MountData/yaolu/LLM_pretrained/Meta-Llama-3.1-8B-Instruct/models--meta-llama--Meta-Llama-3.1-8B-Instruct/snapshots/8c22764a7e3675c50d4c7c9a4edb474456022b16/
